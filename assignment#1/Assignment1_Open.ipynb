{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | <p style=\"text-align: left\">Matr.-No.</p> |\n",
    "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
    "| <p style=\"text-align: left\">*Cesar Miguel*</p>| <p style=\"text-align: left\">*Valdez Cordova*</p> | <p style=\"text-align: left\">*K12046803*</p>  |\n",
    "| <p style=\"text-align: left\">*Ionelia*</p>| <p style=\"text-align: left\">*Buzatu*</p> | <p style=\"text-align: left\">*k12008243*</p>  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">344.063: Special Topics - Natural Language Processing with Deep Learning (SS2022)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 1: Open</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Author:** Navid Rekab-saz<br>\n",
    "**Email:** navid.rekabsaz@jku.at<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-dummy\"><li style=\"font-size:large;font-weight:bold\">Task A: Collection Processing and Dummy Baseline (10 points)</li></a>\n",
    "    <a href=\"#section-model1\"><li style=\"font-size:large;font-weight:bold\">Task B: Implementation of Model I (15 points)</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Assignment objective\n",
    "This Notebook provide a general instruction for the Open assignment. This Notebook should encompas all aspects of the assignment such as the implemented codes and reports. The cells can contains code, reports, charts, tables, or any other material, required for the assignment. Cover the questions/points, mentioned in the tasks, but also add any necessary point for understanding your experiments. Try to provide the solutions in a clear, and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment with the author(s) of the assignment.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Selected NLP Task and Test Collection \n",
    "\n",
    "In this assignment, you can approach any natural language processing task, such as text summarization, question answering, machine translation, etc. To do the assignment, you should first select an **available standard test collection** for the task of your choice. A standard test collection means a dataset that provides training/validation/test sets, and has clearly defined methods/metrics for performance evaluation. Examples of such collections are the ones in various ML challenges (e.g. in Kaggle).\n",
    "\n",
    "If you have any doubts or questions about the selected collection, feel free to resolve it with the lecturer(s) and tutor(s): <navid.rekabsaz@jku.at>, <shahed.masoudian@jku.at>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7) and `PyTorch` (>1.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `transformer`, `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook. \n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Publishing Experiments Results\n",
    "\n",
    "It is encouraged that you log and store any information about the training and evaluation of the models in an ML dashboard like [`TensorBoard`](https://www.tensorflow.org/tensorboard) or [`wandb`](https://wandb.ai/site). This can contain any important aspect of training such as the changes in the evaluation results on validation, training loss, or learning rate. \n",
    "\n",
    "To this end, in the case of `TensorBoard`, after finalizing all experiments and cleaning any unnecessary experiment, publish the log files results through [`TensorBoard.dev`](https://tensorboard.dev). A simple way of doing it is by running the following command in the folder of log files:\n",
    "\n",
    "`tensorboard dev upload --name my_exp --logdir path/to/output_dir`\n",
    "\n",
    "`TensorBoard.dev` uploads the necessary files and provides a URL to see the TensorBoard's console. Insert the URL in the cell below.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**URL :** *EDIT!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-dummy\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Collection Processing and Dummy Baseline (10 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "The objective of this task is to load and process the collection, to implement a simple dummy baseline, followed by its evaulation. Indeed, the actual functionality of each part depends on the selected collection. However, the following general steps are expected in the provided solution. \n",
    "\n",
    "**Loading the collection and preprocessing the data (2 point).** \n",
    "\n",
    "**Defining a dummy baseline and training it (2 point):** A dummy baseline can be any non-deep-learning model, which is considered as a weak baseline for further comparisons. This model can be a classical machine learning algorithm (like by using linear regression), or even the models that ignore input features such as the ones in [`DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html).\n",
    "\n",
    "**Evaluation (2 point).**\n",
    "\n",
    "**Overall functionality (2 point).**\n",
    "\n",
    "**Reporting (2 point):** During loading and processing the collection, provide sufficient information and examples about the data and the applied processing steps. Report the evaluation results of the baseline model on the validation and test set in a table.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingmolecules import MatModel, MatFeaturizer, MatConfig\n",
    "\n",
    "import getpass\n",
    "whoami = getpass.getuser()\n",
    "print(f\"user: {whoami}\")\n",
    "\n",
    "# The following import works only from the source code directory:\n",
    "USERS_PATH_TO_REPO = {'semibah': '/home/semibah/huggingmolecules', 'ionelia': '/home/ionelia/pycharm-projects/huggingmolecules', 'other_user': 'please fill in here path'}\n",
    "try:\n",
    "    sys.path.append(USERS_PATH_TO_REPO[whoami])\n",
    "except KeyError:\n",
    "    raise(\"who are you? - add your username to the dict above.\")\n",
    "    \n",
    "from experiments.src import TrainingModule, get_data_loaders\n",
    "from experiments.src.training import training_metrics\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torch.nn import MSELoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from torchinfo import summary\n",
    "from tdc.utils import retrieve_label_name_list\n",
    "from typing import Tuple, List, Optional, Any\n",
    "import inspect\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.metrics import MeanSquaredError, Metric\n",
    "from pytorch_lightning.metrics.functional.classification import auroc\n",
    "\n",
    "from tdc.single_pred import ADME\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "\n",
    "# the models used in task A\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show **two problems of drug discovery** and apply in task A a linear regression for the **classification task** and tree regression model for the **regression task**. \\\n",
    "We will then implement a version of the recent Transformer algorithm adapting it to our drug discovery tasks. For each task there is a short description and an example of how it looks like. \\\n",
    "The loading of the data uses two packages: **tdc and huggingmolecules**, in **task A** for simplicity we use tdc and in **task B** because of the transformers we use: \\\n",
    "https://tdcommons.ai/single_pred_tasks/adme/#hydration-free-energy-freesolv but essentially they load the same data with the difference that tdc addapts it to the transformers architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions we will need later\n",
    "\n",
    "def drug_descriptors(drugs):\n",
    "    \"\"\"\n",
    "    used to preprocess drug discovery data. this kind of data comes as a string format\n",
    "    and here we extract information of each drug with the help of rdkit package. \n",
    "    each desciptor is an attribute of the drug e.g. the pH and, \n",
    "    all together, those attributes form the input for the model for a single sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    def descriptors_array(mol):\n",
    "        descriptors = np.array(get_descriptors.ComputeProperties(mol))\n",
    "        return descriptors\n",
    "    \n",
    "    if isinstance(drugs, str):\n",
    "        mol = Chem.MolFromSmiles(drug)\n",
    "        drug_descriptors = []\n",
    "        if mol:\n",
    "            drug_descriptors = descriptors_array(mol) \n",
    "        return drug_descriptors\n",
    "    else:\n",
    "        dataset_descriptors = []\n",
    "        for drug in drugs:\n",
    "            mol = Chem.MolFromSmiles(drug)\n",
    "            descriptors = descriptors_array(mol)\n",
    "            if len(descriptors):\n",
    "                dataset_descriptors.append(descriptors)\n",
    "        return dataset_descriptors  \n",
    "    \n",
    "def regression_task(model, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    train a regression model.\n",
    "    return: the mean absolute error of the testset. \n",
    "    \"\"\"\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_freesolv_test)\n",
    "    mean_absolute_error = mae(y_test, y_pred)\n",
    "    return mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification task\n",
    "\n",
    "**HIA is a classification task and stands for human intestinal absorption.**\n",
    "\n",
    "**Dataset Description**: When a drug is orally administered, it needs to be absorbed from the human gastrointestinal\n",
    "system into the bloodstream of the human body. This ability of absorption is called human intestinal absorption\n",
    "(HIA) and it is crucial for a drug to be delivered to the target.\n",
    "\n",
    "**Task Description**: Binary classification. Given a drug SMILES string, predict the activity of HIA.\n",
    "\n",
    "**Dataset Statistics**: 578 drugs.\n",
    "\n",
    "**Suggested data split**: scaffold split.\n",
    "\n",
    "**Evaluation Metric**: AUROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# loading classification data and split it into train, validation and test.\n",
    "data_hia = ADME(name = 'HIA_Hou')\n",
    "split_data_hia = data_hia.get_split(method='scaffold', frac=[0.7, 0.0, 0.3])\n",
    "hia_train, hia_valid, hia_test = split_data_hia['train'], split_data_hia['valid'], split_data_hia['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_names = list(Chem.rdMolDescriptors.Properties.GetAvailableProperties())\n",
    "get_descriptors = Chem.rdMolDescriptors.Properties(descriptor_names)\n",
    "mol = Chem.MolFromSmiles(hia_train.Drug[0])\n",
    "mol\n",
    "descriptors = []\n",
    "if mol:\n",
    "    descriptors = np.array(get_descriptors.ComputeProperties(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data.\n",
    "x_hia_train, x_hia_test = drug_descriptors(hia_train.Drug), drug_descriptors(hia_test.Drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310344827586207\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_hia_train, hia_train.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy classification task:\", acc(hia_test.Y, lda.predict(x_hia_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression task freesolv\n",
    "\n",
    "**Dataset Description**: The Free Solvation Database, FreeSolv(SAMPL), provides experimental and calculated hydration free energy of small molecules in water. The calculated values are derived from alchemical free energy calculations using molecular dynamics simulations. From MoleculeNet.\n",
    "\n",
    "**Task Description**: Regression. Given a drug SMILES string, predict the activity of hydration free energy. TODO what is hydration free energy?\n",
    "\n",
    "**Dataset Statistics**: 642 drugs.\n",
    "\n",
    "**Evaluation Metric**: mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 14935.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data_freesolv = ADME(name = 'hydrationfreeenergy_freesolv')\n",
    "split_data_freesolv = data_freesolv.get_split(method='scaffold', frac = [0.7, 0.0, 0.3])\n",
    "freesolv_train, freesolv_valid, freesolv_test = split_data_freesolv['train'], split_data_freesolv['valid'], split_data_freesolv['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_freesolv_train, x_freesolv_test = drug_descriptors(freesolv_train.Drug), drug_descriptors(freesolv_test.Drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.63802844623862\n",
      "2.5673125\n",
      "1.6086259375000005\n",
      "2.3152125\n",
      "2.1963840625\n",
      "2.1567131183678336\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression, DecisionTreeRegressor, ExtraTreesRegressor, KNeighborsRegressor, RandomForestRegressor, GradientBoostingRegressor]\n",
    "for model in models:\n",
    "    regression_task(model(), x_freesolv_train, freesolv_train.Y, x_freesolv_test, freesolv_test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6296346874999998\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor()\n",
    "regression_task(model, x_freesolv_train, freesolv_train.Y, x_freesolv_test, freesolv_test.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Report Results Task A**\n",
    "\n",
    "| set-data | \n",
    "|---|\n",
    "|validation|\n",
    "| test |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-model1\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Implementation of `Model I` (15 points)</li></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "The objective of this task is to implement the first deep learning model, referred to as `Model I`, together with some architectural variations of this model. The task should cover the following points:\n",
    "\n",
    "**Implementing `Model I` (7 points):** The model can use any of the architectures discussed in the course such as CNNs, RNNs, Attention Networks, Transformers, pretrained Large LMs.\n",
    "\n",
    "**Model variations (6 points):** Implement **three variations** of `Model I`. Each variation applies only one change to the baseline architecture, making it possible to study the effect of the change. A variation can be a change in for instance the architecture (like number of layers, size of the embeddings, architecture-specific variants, etc.), optimization methods, or regularization approaches. The code of all variations should be inside the code of `Model I`, and executing a variation should be done by simply passing the corresponding parameters of the variation to the model. \n",
    "\n",
    "\n",
    "**Reporting and discussion (2 points):** Report the evaluation results of all the variations in a table and also in a plot, accompanied with the result of the dummy baseline. Discuss which variation(s) appear to be the most effective one(s). Explain your take.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freesolv_featurizer = MatFeaturizer.from_pretrained('mat_masking_200k')\n",
    "freesolv_train, freesolv_valid, freesolv_test = get_data_loaders(freesolv_featurizer,\n",
    "                                          batch_size=32,\n",
    "                                          task_name='ADME',\n",
    "                                          dataset_name='hydrationfreeenergy_freesolv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hia dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results discussion**\n",
    "\n",
    "For both task the regression task turned out to be quite challenging for both the linear model and the transformer. \\\n",
    "Instead, for the classfication task, the trasformer outperforms the linear model significantly by TODO?. \n",
    "\n",
    "| Dataset | Metric | Linear model | Transformer\n",
    "|---|:---| :---:|:---:\n",
    "|HIV| AUROC | 0.93 | TODO\n",
    "|FreeSolv| MAE | 1.63 | TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
